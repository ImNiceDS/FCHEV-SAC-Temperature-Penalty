{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOezWGehls48tm3Bn4ce91z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7w8ICneTK5iP"},"outputs":[],"source":["# running environment of DP\n","import numpy as np\n","from common.utils import get_driving_cycle, get_acc_limit\n","\n","\n","class DP_Env:\n","    def __init__(self, scenario_name):\n","        # speed list\n","        self.speed_list = get_driving_cycle(cycle_name=scenario_name)\n","        self.acc_list = get_acc_limit(self.speed_list, output_max_min=False)\n","        self.abs_spd_MAX = max(abs(self.speed_list))\n","        self.abs_acc_MAX = max(abs(max(self.acc_list)), abs(min(self.acc_list)))\n","        self.time_steps = len(self.speed_list)\n","        self.trip_length = sum(self.speed_list)/1000     # km\n","        # state space\n","        self.state_dim = 1      # SoC\n","        self.state_increment = 0.005        # this is OK\n","        self.state_init = 0.5\n","        self.state_max = 0.55\n","        self.state_min = 0.01\n","        self.states = np.arange(self.state_min, self.state_max, self.state_increment)\n","        self.state_num = len(self.states)\n","        # action space\n","        self.action_dim = 1  # P_fcï¼Œ kW\n","        self.action_number = 5\n","        self.actions = np.linspace(0, 1, self.action_number+1, dtype=np.float32)\n","        # value function\n","        self.values = np.zeros(self.state_num+1, dtype=np.float32)\n","        # policy\n","        self.policy = np.zeros(self.time_steps, dtype=np.float32)\n","\n","\n","if __name__ == '__main__':\n","    print(\"---debug---\")\n","    scenario_name = 'CLTCP_WVUINTER'\n","    dp_env = DP_Env(scenario_name)\n","    print('scenario_name: %s'%scenario_name)\n","    print(dp_env.actions)\n","    print(60*dp_env.actions)\n","    print(dp_env.states)\n","    print('\\naction-shape', dp_env.actions.shape)\n","    print('\\nstate-shape', dp_env.states.shape)\n","    print('\\nstate*shape', dp_env.states.shape[0]*dp_env.actions.shape[0])\n","    print('\\ntime-step', dp_env.time_steps)\n","    print('\\nstep %d * state %d * action %d: %d'%\n","          (dp_env.time_steps, dp_env.states.shape[0], dp_env.actions.shape[0],\n","           dp_env.states.shape[0]*dp_env.actions.shape[0]*dp_env.time_steps))\n",""]}]}