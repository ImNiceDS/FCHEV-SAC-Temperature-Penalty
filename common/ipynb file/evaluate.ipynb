{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkIo0BIVpGRt4dbp66D+C5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S-6FDOoELMey"},"outputs":[],"source":["from tqdm import tqdm\n","import os\n","import torch\n","import numpy as np\n","import time\n","import scipy.io as scio\n","from common.sac import SAC\n","\n","class Evaluator:\n","    def __init__(self, args, env):\n","        self.args = args\n","        self.eva_episode = args.evaluate_episode\n","        self.episode_step = args.episode_steps\n","        self.env = env\n","        self.DRL_agent = SAC(args)      # TODO 定义不同的DRL智能体\n","\n","        self.save_path = self.args.eva_dir+'/'+self.args.scenario_name\n","        if not os.path.exists(self.save_path):\n","            os.makedirs(self.save_path)\n","        self.save_path_episode = self.save_path+'/episode_data'\n","        if not os.path.exists(self.save_path_episode):\n","            os.makedirs(self.save_path_episode)\n","\n","    def evaluate(self):\n","        average_reward = []  # average_reward of each episode\n","        fuel_100 = []  # equivalent hydrogen consumption per 100 km\n","        real_h2_100 = []\n","        money_100 = []  # money spent per 100 km\n","        Batt_SoH = []\n","        FCS_SOH = []\n","        for episode in tqdm(range(self.eva_episode)):\n","            state = self.env.reset()  # reset the environment\n","            setp_reward = []\n","            # data being saved in .mat\n","            episode_info = {'T_mot': [], 'W_mot': [], 'mot_eff': [], 'P_mot': [],\n","                            'P_fc': [], 'P_fce': [], 'fce_eff': [], 'FCS_SOH': [],\n","                            'P_dcdc': [], 'dcdc_eff': [], 'FCS_De': [], 'travel': [],\n","                            'd_s_s': [], 'd_low': [], 'd_high': [], 'd_l_c': [],\n","                            'EMS_reward': [], 'soc_cost': [], 'h2_equal': [], 'h2_fcs': [],\n","                            'money_cost': [], 'h2_money': [], 'batt_money': [], 'fcs_money': [],\n","                            'SOC': [], 'SOH': [], 'I': [], 'I_c': [], 'money_cost_real': [],\n","                            'cell_OCV': [], 'cell_Vt': [], 'cell_V_3': [],\n","                            'cell_power_out': [], 'P_batt': [], 'tep_a': [], 'dsoh': []}\n","            start_time = time.time()\n","            for episode_step in range(self.episode_step):\n","                with torch.no_grad():\n","                    raw_action = self.DRL_agent.select_action(state, evaluate=True)\n","                action = raw_action\n","                state_next, reward, done, info = self.env.step(action, episode_step)\n","                state = state_next\n","                # save data\n","                for key in episode_info.keys():\n","                    episode_info[key].append(info[key])\n","                setp_reward.append(reward)\n","                # save data in .mat\n","                if episode_step+1 == self.episode_step:\n","                    datadir = self.save_path_episode+'/data_ep%d.mat'%episode\n","                    scio.savemat(datadir, mdict=episode_info)\n","                    # print\n","                    f_travel = info['travel']/1000\n","                    h2 = sum(episode_info['h2_fcs'])  # g\n","                    eq_h2 = sum(episode_info['h2_equal'])  # g\n","                    money = sum(episode_info['money_cost'])  # RMB\n","                    h2_100 = h2/f_travel*100\n","                    eq_h2_100 = eq_h2/f_travel*100\n","                    m_100 = money/f_travel*100\n","                    fuel_100.append(eq_h2_100)\n","                    real_h2_100.append(h2_100)\n","                    money_100.append(m_100)\n","                    soc = info['SOC']\n","                    bat_soh = info['SOH']\n","                    fcs_soh = info['FCS_SOH']\n","                    Batt_SoH.append(bat_soh)\n","                    FCS_SOH.append(fcs_soh)\n","                    print('\\nepi %d: travel %.3fkm, SOC %.4f, Bat-SOH %.6f, FCS-SOH %.6f'\n","                          %(episode, f_travel, soc, bat_soh, fcs_soh))\n","                    print('epi %d: h2_100km %.2fg, money_100km ￥%.2f'%(episode, eq_h2_100, m_100))\n","\n","            end_time = time.time()\n","            spent_time = end_time-start_time\n","            # save reward\n","            ep_r_mean = np.mean(setp_reward)\n","            average_reward.append(ep_r_mean)\n","            # print\n","            print('episode %d: reward %.3f, time spent: %.3fs'\n","                  %(episode, ep_r_mean, spent_time))\n","\n","        scio.savemat(self.save_path+'/reward.mat', mdict={'reward': average_reward})\n","        scio.savemat(self.save_path+'/eq_h2_100.mat', mdict={'eq_h2_100': fuel_100})\n","        scio.savemat(self.save_path+'/money.mat', mdict={'money': money_100})\n","        scio.savemat(self.save_path+'/Batt_SoH.mat', mdict={'Batt_SoH': Batt_SoH})\n","        scio.savemat(self.save_path+'/FCS_SOH.mat', mdict={'FCS_SOH': FCS_SOH})\n","        scio.savemat(self.save_path+'/h2_100.mat', mdict={'real_h2_100': real_h2_100})"]}]}